{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Python for DATA SCIENCE</h1><Br/>\n",
    "<img src=\"https://goo.gl/ZKX5FF\" style=\"width:15%; float:centre\"><Br/>\n",
    "<h2 align=\"center\">Dr Mazen Gabriel Alhrishy</h2>\n",
    "<h5 align=\"center\"><i>MAZEN.ALHRISHY@GMAIL.COM</i></h5><Br/>\n",
    "\n",
    "<table width=25%>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"https://goo.gl/BTtR3C\"><img src=\"https://goo.gl/rMsKok\"></a>\n",
    "        </td>\n",
    "        <td>\n",
    "            <a href=\"https://goo.gl/XaRDbH\"><img src=\"https://goo.gl/KyMZcj\"></a>\n",
    "        </td>\n",
    "        <td>\n",
    "            <a href=\"https://goo.gl/9uCqS6\"><img src=\"https://goo.gl/a8gcDK\"></a>\n",
    "        </td>\n",
    "        <td>\n",
    "            <a href=\"https://goo.gl/bnt2EL\"><img src=\"https://goo.gl/1rT18x\"></a>\n",
    "        </td>\n",
    "        <td>\n",
    "            <a href=\"https://goo.gl/VmfU3S\"><img src=\"https://goo.gl/WFFkxn\"></a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 8- Pandas for Data Analysis\n",
    "\n",
    "> ## [I- Introduction](#I)\n",
    "> ## [II- Fundamental data structures](#II)\n",
    "> ## [III- Selecting data](#III)\n",
    "> ## [IV- Essential functionality](#IV)\n",
    "> ## [V- Working with missing data](#V)\n",
    "> ## [VI- Reading and writing data in text format](#VI)\n",
    "> ## [VII- Visualization](#VII)\n",
    "\n",
    "> ### [- Exercises](#exercises)\n",
    "> ### [- Solutions](#solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## I- Introduction <a id='I'></a>\n",
    "\n",
    "> ## [1. History](#I-1)\n",
    "> ## [2. Installation](#I-2)\n",
    "> ## [3. Motivation](#I-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- History <a id='I-1'></a>\n",
    "\n",
    "* Statistician Wes McKinney started working on pandas in 2008 while at AQR Capital Management out of the need for a high performance, flexible tool to perform **quantitative analysis on financial data**. By the end of 2009 it had been open sourced. By 2010, McKinney left AQR to pursue a PhD in statistics, leaving him little time to work on improving Pandas\n",
    "\n",
    "<img src=\"https://goo.gl/JM4fN6\" style=\"width:30%; border-radius:50%; float:left; padding:20px 30px 20px 30px\"/>\n",
    "\n",
    "<br><br>\n",
    "“I felt that Python as a language was facing an existential crisis... Python was either going to become relevant as a statistical computing language or it wasn’t, and I felt it had so much potential. I decided to drop out of graduate school to work on Pandas as much as possible...”\n",
    "\n",
    "— Wes McKinney (Creator and Benevolent Dictator For Life)\n",
    "\n",
    "— Author of __[Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do)__\n",
    "\n",
    "<br><br><br><br><br>\n",
    "* The library’s name derives from **pan**el **da**ta, a common term for multidimensional data sets used in statistics and econometrics\n",
    "\n",
    "\n",
    "* Pandas is written primarily in pure Python, but it also makes heavy use of NumPy and other extension code to provide good performance even for large panels\n",
    "\n",
    "\n",
    "* __[Pandas website](https://pandas.pydata.org/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Installation <a id='I-2'></a>\n",
    "\n",
    "* Pandas requires a number of dependencies. The Anaconda Python distribution already provides pandas built-in\n",
    "\n",
    "* If you've created a basic virtual environment, you can get pandas using conda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! conda install pandas --y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To verify the package was installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To import into a Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Motivation <a id='I-3'></a>\n",
    "\n",
    "* Pandas enables you to carry out your **entire data analysis workflow** in Python without having to switch to a more domain specific language like R. This includes: \n",
    "    - Data munging and preparation<sup>1</sup>\n",
    "    - Data analysis<sup>2</sup>\n",
    "    - Data modeling<sup>3</sup>\n",
    "\n",
    "\n",
    "<sup>1</sup>Something to keep in mind is that in pandas, data alignment is intrinsic. The link between labels and data will not be broken unless done so explicitly\n",
    "\n",
    "<sup>2</sup>Although pandas uses/adopts NumPy, the biggest difference is that, pandas is developed to deal with heterogeneous data; whereas Numpy is more suited to deal with homogeneous numerical array data\n",
    "\n",
    "<sup>3</sup>pandas does not implement significant modelling functionality outside of linear and panel regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## II- Fundamental data structures <a id=\"II\"></a>\n",
    "\n",
    "There are two primary data structures in pandas you need to know about:\n",
    "\n",
    "> ### [1- Series](#II-1)\n",
    "> ### [2- DataFrame](#II-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Series <a id='II-1'></a>\n",
    "\n",
    "* A __[series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html)__ is a **1d array-like** structure. Like a normal array, Series contains a **sequence of values**, however in addition, each value also has an associated label that is also called an **index**\n",
    "\n",
    "\n",
    "* The basic method to create a Series object is:\n",
    "\n",
    "> s = pd.Series(data)\n",
    "\n",
    "Data can be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1- List of values_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([4, 7, -5])\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first column represents the index while the second represent the values\n",
    "\n",
    "* Here, an index was automatically created and assigned to each value. However, we can specify indexes with the **index** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([4, 7, -5], index=['a', 'b', 'c'])\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are several types of indexes that we can use. For example, for fixed frequency dates, we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20180618', periods=3)\n",
    "s1 = pd.Series([4, 7, -5], index=dates)\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2- Python dictionary_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2 = pd.Series({'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000})\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The index in the resulting Series will be the dict's keys in sorted order. If we want a specific order we can provide the **index** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2 = pd.Series({'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}, index=['Texas', 'Ohio', 'Oregon', 'Utah'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3- Numpy array_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "s3 = pd.Series(np.random.randn(3), index=['a', 'b', 'c'])\n",
    "s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- DataFrame <a id='II-2'></a>\n",
    "\n",
    "A __[DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)__ is an **nd array-like** structure. It contains **columns of values**<sup>+</sup>. Each value has associated **row index** and **column index** (think of it as a spreadsheet)\n",
    "\n",
    "<sup>+</sup> Think of a DataFrame as a dict of Series, all sharing the same index\n",
    "\n",
    "* The basic method to create a DataFrame object is:\n",
    "\n",
    "> df = pd.DataFrame(data)\n",
    "\n",
    "Like Series, DataFrame accepts many different kinds of input. The most common ones are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1- A dict of equal-length lists or NumPy arrays:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],  # values as a list\n",
    "       'year': [2000, 2001, 2002, 2001, 2002, 2003],  # values as a NumPy array\n",
    "       'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}  # values as a Series\n",
    "\n",
    "df1 = pd.DataFrame(data)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The resulting DataFrame has automatically created and assigned the row index, and the **columns will be sorted** in order. Similar to Series we can specify the indexes using **index**. We can also specify the order of columns by using the **columns** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data, index=['one', 'two', 'three', 'four', 'five', 'six'], columns=['year', 'state', 'pop'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2- A dict of dicts_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop = {'Nevada':{2001: 2.4, 2002: 2.9},\n",
    "       'Ohio':{2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "\n",
    "df2 = pd.DataFrame(pop)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **outer dict keys** are interpreted **as columns indexes** and the **inner keys as row indexes**. Also, we can see that any missing values are filled with **NaN** (Not a Number) value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In both Series and DataFrame, you can get values using the **values** attribute (represented as a numpy object), and the row indexes using the **index** attribute (as an index object). You can also get the column indexes for a DataFrame using the **columns** attribute (as an index object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(s2.values)\n",
    "print(s2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df2.values)\n",
    "print(df2.index)\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## III- Selecting data <a id='III'></a>\n",
    "\n",
    "There are a large number of ways to select data. We will cover the most common ones\n",
    "\n",
    "        Keep in mind that the result will always be:\n",
    "        - A NumPy scaler if a single value is selected\n",
    "        - A Series if multiple values from one row/column are selected (i.e. 1d array)\n",
    "        - A DataFrame if multiple values from multiple rows/columns are selected (i.e. nd array)\n",
    "\n",
    "        Remembering this will help you to know how to process the result!\n",
    "\n",
    "> ### [1- Columns selection](#III-1)\n",
    "> ### [2- Rows selection](#III-2)\n",
    "> ### [3- Combined selection](#III-3)\n",
    "> ### [4- Boolean selection](#III-4)\n",
    "\n",
    "* Let's consider the following DataFrame and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(16).reshape(4, 4), index=['Ohio', 'Colorado', 'Utah', 'New York'], \n",
    "                  columns=['one', 'two', 'three', 'four'])\n",
    "\n",
    "s = pd.Series([1, 5, 9, 13], index=['Ohio', 'Colorado', 'Utah', 'New York'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Columns selection <a id='III-1'></a>\n",
    "\n",
    "> - A **single column** (i.e. 1d array) can be selected **as a Series** or **as a DataFrame**  \n",
    "- **Multiple columns** (i.e. nd array) can only be selected **as a DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1- For single column_**\n",
    "\n",
    "* A **single column** can be selected **as a Series** either by dict-like notation or by attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col2 = df['two'] # dict notation which is equivalent to selecting by attribute df.two\n",
    "col2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **column** can also be selected **as a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col2 = df[['two']]\n",
    "col2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2- For Multiple columns_**\n",
    "\n",
    "* **Multiple columns** can only be selected **as a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col23 = df[['two', 'three']]\n",
    "col23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Rows selection <a id='III-2'></a>\n",
    "\n",
    "> The method to select rows depends on the data structure:  \n",
    "- A **Series** behaves in similar way to NumPy for indexing  \n",
    "- A **DataFrame** does not behaves like NumPy. For that we need to use the special indexing operators **iloc** and **loc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1- For Series_**\n",
    "\n",
    "* In Series, rows can be indexed in a similar way to NumPy using integers (end-point is exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the second row, we can use its **index** (i.e. integer-indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row2 = s[1]\n",
    "row2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get first 3 rows, we can slice by **index** as well (i.e. integer-slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row13 = s[:3]\n",
    "row13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Another option to select rows in Series is by **label** (end-point is inclusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the second row, we can use its **label** (i.e. label-indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row2 = s['Colorado']\n",
    "row2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get first 3 rows, we can slice by **label** as well (i.e. label-slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row13 = s['Ohio':'Utah']\n",
    "row13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2- For DataFrame_**\n",
    "\n",
    "* The special indexing operators **iloc** and **loc** enable selecting rows from a DataFrame with NumPy like notation using either: \n",
    "    - iloc integer-indexing\n",
    "    - loc label-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1- iloc integer-indexing_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the second row we can use its **integer** position with **iloc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row2 = df.iloc[1]\n",
    "row2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first 3 rows, we can slice by **integer** position with **iloc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row13 = df.iloc[:3]  # slicing is also possible with normal integer-slicing (df[:3])\n",
    "row13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2- loc label-indexing_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the second row, we can use its **label with loc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row2 = df.loc['Colorado']\n",
    "row2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get first 3 rows, we can slice by **label with loc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row13 = df.loc['Ohio':'Utah']  # slicing is also possible with normal label-slicing (df['Ohio':'Utah'])\n",
    "row13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Combined selection <a id='III-3'></a>\n",
    "\n",
    "> Now that we know the basics of column/row selections, we can combine these in different ways to get the desired values. Remember, the result will always be:\n",
    "        - A NumPy scaler if a single value is selected\n",
    "        - A Series if multiple values from one row/column are selected (i.e. 1d array)\n",
    "        - A DataFrame if multiple values from multiple rows/columns are selected (i.e. nd array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1- Selecting a single value_**\n",
    "\n",
    "* Second column, second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df['two'][1])  # get column 'two' as Series > get second element \n",
    "print('---')\n",
    "print(df.iloc[1, 1])  # get second row as Series > get second element (df.iloc[1][1])\n",
    "print('---')\n",
    "print(df.loc['Colorado', 'two']) # get 'Colorado' row as Series > get 'two' element (df.loc['Colorado'].loc['two'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2- Selecting multiple values from one row/column_**\n",
    "\n",
    "*  Second column, first 3 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df['two'][:3])  # df['two'] then [:3]\n",
    "print('---')\n",
    "print(df.iloc[:3, 1])  # df.iloc[:3].T then iloc[1]\n",
    "print('---')\n",
    "print(df.loc[:'Utah', 'two'])  # df.loc[:'Utah'] then ['two']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3- Selecting multiple values from multiple rows/columns_**\n",
    "\n",
    "*  Second to third column, first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df[['two', 'three']][:3])  # df[['two', 'three']] then [:3]\n",
    "print('---')\n",
    "print(df.iloc[:3, 1:3])  # df.iloc[:3].T then iloc[1:3].T\n",
    "print('---')\n",
    "print(df.loc[:'Utah', 'two':'three'])  # df.loc[:'Utah'] then [['two','three']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Boolean selection <a id='III-4'></a>\n",
    "\n",
    "> All previous selections can be used with Boolean conditions to create a Truth mask (True, False). Depending on the selection made, masks can be either:\n",
    "    - Series masks\n",
    "    - DataFrame masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1-Using a Series mask_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select rows where second column > 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df['two'] > 5\n",
    "print(mask)\n",
    "print('---')\n",
    "print(df[mask])  # mask index aligned with the DataFrame index (should be applied column-wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **isin()** method can be used to specify a list of values for the mask  \n",
    "Select rows where second column is 5 or 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df['two'].isin([5, 9])\n",
    "print(mask)\n",
    "print('---')\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select columns where second row > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df.iloc[1] > 5  # equivalent to df.loc['Colorado'] > 5\n",
    "print(mask)\n",
    "print('---')\n",
    "print(df.loc[:, mask]) # mask index aligned with the DataFrame columns (should be applied row-wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2-Using a DataFrame mask_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select all values which are > 5\n",
    "\n",
    "values where mask is False are replaced with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df > 5\n",
    "print(mask)\n",
    "print('---')\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select values in the second and third columns which are > 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df[['two', 'three']] > 5 \n",
    "print(mask)\n",
    "print('---')\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select values in the first 3 rows, second to third column which are > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df.iloc[:3, 1:3] > 5  # equivalent to df.loc[:'Utah', 'two':'three']\n",
    "print(mask)\n",
    "print('---')\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## IV- Essential functionality <a id='IV'></a>\n",
    "\n",
    "> ### [1- Reindexing](#IV-1)\n",
    "> ### [2- Sorting](#IV-2)\n",
    "> ### [3- Basic arithmetic](#IV-3)\n",
    "> ### [4- NumPy universal functions (ufunc)](#IV-4)\n",
    "> ### [5- Computing descriptive statistics](#IV-5)\n",
    "> ### [6- Function application and mapping](#IV-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9.).reshape(3, 3), index=['d', 'a', 'b'], \n",
    "                  columns=['A', 'B', 'C'])\n",
    "\n",
    "df2 = pd.DataFrame(np.arange(9.,18.).reshape((3, 3)), index=['b', 'd', 'c'],\n",
    "                   columns=['C', 'A', 'E'])\n",
    "\n",
    "s1 = pd.Series([0.0, 1.0, 2.0], index=['D', 'A', 'E'])\n",
    "\n",
    "s2 = pd.Series([6.0, 1.0, 4, 3.0], index=['D', 'A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Reindexing <a id=\"IV-1\"></a>\n",
    "\n",
    "> A Pandas object can be reindexed with the **reindex()** method. A new object is returned with the data rearranged according to the new index. Missing values are replaced with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df1.reindex(index=['a', 'b', 'c', 'd'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The columns can also be reindexed with the **columns** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df2.reindex(index=['a', 'b', 'c', 'd'], columns=['A', 'B', 'C', 'D', 'E'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Sorting <a id=\"IV-2\"></a>\n",
    "\n",
    "> Pandas objects can be sorted either:\n",
    "    - By index using the sort_index()\n",
    "    - By value using the sort_values()  \n",
    "    \n",
    "Both methods return a new object sorted in an ascending order by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort **Series** by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort **Series** by value in a descending order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To sort a **DataFrame** by value, we need to specify a column to use its data for sorting. This is done using the **by** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.sort_values(by='A', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multiple columns can also be used for sorting by values in DataFrames. Data is sorted according to the first column values, in case of a tie, the second column values are used to sort, and do on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.loc['c', 'A'] = 13.0  # introduce a tie\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.sort_values(by=['A', 'C'])  # sort by 'A' values first. In case of duplicates in 'A', sort by 'C' values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For **DataFrames**, we can also sort columns by setting the **axis** argument value to **1** (i.e. along columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Basic arithmetic <a id=\"IV-3\"></a>\n",
    "\n",
    "> When performing basic arithmetic between 2 Pandas objects, index pairs will always be aligned. If index pairs are not the same, the result will be their union (similar to outer join in database handling) replacing missing values with NaN. Arithmetic can be:\n",
    "    - Between 2 Series\n",
    "    - Between 2 DataFrames\n",
    "    - Between a Series and a DataFrame\n",
    "    \n",
    "* Basic arithmetic operators are: $+$, $-$, $*$, $/$, $//$, $\\%$, $**$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1-Between 2 Series_**: alignment is performed along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(s1)\n",
    "print('---')\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 - s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2-Between 2 DataFrames_**: alignment is performed along both rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print('---')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3-Between a Series and a DataFrame_**: the Series index is aligned with the DataFrame columns, and arithmetic is performed row-wise (similar to NumPy behaviour known as broadcasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print('---')\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 / s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- NumPy universal functions (ufunc) <a id=\"IV-4\"></a>\n",
    "\n",
    "> Because Pandas uses NumPy to enhance performance, all NumPy ufunc we talked about before (a function that operates on nd-arrays **element-wise**) can be used on Pandas objects with built-in handling for missing data. The result will be another Pandas object with the **indexes preserved**\n",
    "\n",
    "* In fact, all basic arithmetic above utilizes NumPy math ufunc. For example when adding the 2 DataFrames above, the **add()** ufunc was called under the hood!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.add(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some example ufunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.square(df1)  # square the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isnan(df1 - df2)  # truth value whether NaN exists or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.floor(df1 / s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Computing descriptive statistics <a id=\"IV-5\"></a>\n",
    "\n",
    "> Pandas also takes advantage of NumPy to provide a set of statistical methods with built-in handling for missing data. These can be categorized into:\n",
    "    - Reduction statistics\n",
    "    - Summary statistics\n",
    "    \n",
    "    NaN are excluded by defualt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'one':{'a': 1.4, 'b': 7.1, 'c': np.nan, 'd': 0.75},\n",
    "                   'two':{'a': np.nan, 'b': -4.5, 'c': np.nan, 'd': -1.3}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1-Reduction statistics_**: these extract a single value from a Series, or a Series of values from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extrema reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.min()  # return a Series containing columns min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.idxmin()  # return indexes of min values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.max(axis=1)  # return a Series containing rows max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.idxmax(axis='columns')  # return indexes of max values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Statistical reductions: these are the most common used ones but more exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.mean()  # return a Series containing columns mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.median()  # return a Series containing columns median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.std()  # return a Series containing columns standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.count()  # return a Series containing columns number of non-NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.sum()  # return a Series containing columns sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.cumsum()  # return a DataFrame of accumulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2-Summary statistics_**: which produce multiple summary statistics in one shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Function application and mapping <a id=\"IV-6\"></a>\n",
    "\n",
    "> A very useful operation is to apply a custom/anonymous function on a Series or DataFrame. This can be done element-wise, or column-wise using one of the following methods:\n",
    "    - map() is used to apply a function, element-wise, on a Series\n",
    "    - apply() is used to apply a function, column-wise, on a DataFrame\n",
    "    - applymap() is used to apply a function, element-wise, on a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1-map()_**: apply a function that adds 1, element-wise, on a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1.map(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2-apply()_**: apply a function that subtracts the max from the min, column-wise, on a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done row-wise for DataFrames using the **columns** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: x.max() - x.min(), axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3-applymap()_**: apply a function that subtracts the first column's mean, element-wise, on a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = df1['A'].mean()\n",
    "df1.applymap(lambda x: x - mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## V- Working with missing data <a id=\"V\"></a>\n",
    "\n",
    "> There are plenty of methods in Pandas for dealing with missing data. Here are few common ones\n",
    "\n",
    "> ### [1- Filling missing values: fillna](#V-1)\n",
    "> ### [2- Dropping axis with missing data: dropna](#V-2)\n",
    "> ### [3- Interpolation at missing data: interpolate](#V-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'one':{'a': 1.4, 'b': 7.1, 'c': np.nan, 'd': 0.75},\n",
    "                   'two':{'a': np.nan, 'b': -4.5, 'c': np.nan, 'd': -1.3},\n",
    "                   'three':{'a': np.nan, 'b': np.nan, 'c': 0.57, 'd': -0.44},\n",
    "                   'four':{'a': 3, 'b': 2.7, 'c': 0.63, 'd': 2.34}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Filling missing values: fillna  <a id=\"V-1\"></a>\n",
    "\n",
    "> The method **fillna()** can be used to fill in missing values with either:\n",
    "    - Scaler\n",
    "    - Forward or backward value\n",
    "    - Pandas object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1- Scalar filling_**: any value can be used to replace NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.fillna('NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done in most functions that might result in NaN by using the **fill_value** argument. For example, reindex(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2- Forward or backward filling_**: values before or after NaN can be used to replace it. For that, the **method** argument is provided for the **fillna()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For forward filling, **pad** or **ffill** can be assigned to for **method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.fillna(method='ffill')  # equivalent to df4.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For backword filling, **bfill** or **backfill** can be assigned to **method** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.fillna(method='bfill')  # equivalent to df4.bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most functions that might result in NaN has a **method** argument. For example, reindex(method=ffill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3- Pandas object filling_**: usually using a Series. The index of the Series must match the columns of the DataFrame we wish to fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can pass the DataFrame means as a Series to the **fillna** method. This will replace NaN in each column with the mean of that column (or median(), max(), min(), std(), etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.fillna(df4.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Dropping axis with missing data: dropna  <a id=\"V-2\"></a>\n",
    "\n",
    "> The method **dropna()** can be used to simply remove rows/columns which refer to missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all rows that contain NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.dropna(axis=0)  # equivalent to df4.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all columns that contain NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Interpolation at missing data: interpolate  <a id=\"V-3\"></a>\n",
    "\n",
    "> Calling **interpolate()** on a Pandas object, will, by default, perform linear interpolation at missing datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## VI- Reading and writing data in text format <a id=\"VI\"></a>\n",
    "\n",
    "> ### [1- Reading data](#VI-1)\n",
    "> ### [2- Writing data](#VI-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Reading data <a id=\"VI-1\"></a>\n",
    "\n",
    "> A large number of functions for reading tabular data **as a DataFrame** exist in pandas. The most common ones are: \n",
    "    - read_csv() for reading delimited data from a csv file, \n",
    "    - read_excel() for reading tabular data from an excel file\n",
    "    - read_table() for reading delimited data from a file, URL, or a file-like object\n",
    "    \n",
    "* Most of these functions have a large number of optional arguments. We will look into few of these arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a small csv file ex1.csv, which has a header row (the first row in the file)  \n",
    "> To view a csv file we can use the **cat** command on Linux or the **type** command on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! cat Examples/ex1.csv  # for windows: ! type Examples\\\\ex1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic method to read the file is without any arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Examples/ex1.csv')  # for windows: r'Examples\\\\ex1.csv'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the function assigns indexes and reads the first row in the file as the column names  \n",
    "However, some files don't have a header row such as ex2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! cat Examples/ex2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we can either: \n",
    "- Let Pandas assign default column names by using the **header** argument\n",
    "- Or specify column names ourselves by using the **names** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'Examples/ex2.csv', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the default assigned indexes, we can specify one of the columns to be the index (by name or by integer) using the **index_col** argument  \n",
    "In ex2.csv, we want the 'message' column to be the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'], index_col='message')  # or index_col=4\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can skip a list of lines when reading the file using the **skiprows** argument  \n",
    "In ex4.csv, we want to skip the first, third, and fourth lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat Examples/ex4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Examples/ex4.csv', skiprows=[0, 2, 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas by default replaces missing data with NaN  \n",
    "ex5.csv has one empty string, and one NA value which Pandas replaces with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat Examples/ex5.csv  # for windows: ! type Examples\\\\ex5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Examples/ex5.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can handle missing data ourselves using the **na_values** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Examples/ex5.csv', na_values=['NULL', 'foo'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to read only a specific number of rows, we can use the **nrows** argument  \n",
    "In ex6.csv, we want to only read the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Examples/ex6.csv', nrows=5)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Writing data <a id=\"VI-2\"></a>\n",
    "\n",
    "> Data can be written to a large number of delimited formats. The most common one is the csv file format\n",
    "\n",
    "* Let's read some data from ex6.csv then write it into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Examples/ex6.csv', nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic method to write to a file is without any arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('Examples/out.csv')\n",
    "!cat Examples/out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the delimiter is a comma, however, we can use other delimiters using the **sep** argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('Examples/out.csv', sep='|')\n",
    "!cat Examples/out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, both the index and column names are written. Both of these can be disabled using the **index** and **header** arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('Examples/out.csv', index=False, header=False)\n",
    "!cat Examples/out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write only a subset of the columns, and in an order we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('Examples/out.csv', index=False, columns=['key', 'two', 'four'])\n",
    "!cat Examples/out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## VII- Visualization <a id=\"VII\"></a>\n",
    "\n",
    "> Series and DataFrame have a **plot()** method for making some basic plot types. By default, **plot()** makes line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('nbagg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4).cumsum(0),\n",
    "                  columns=['A', 'B', 'C', 'D'],\n",
    "                  index=np.arange(0, 100, 10))\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A handful of plotting styles can be used by providing the **kind** argument to **plot()**. Some include:\n",
    "\n",
    "    - 'bar' or 'barh' for bar plots\n",
    "    - 'hist' for histogram\n",
    "    - 'box' for boxplot\n",
    "    - 'scatter' for scatter plots\n",
    "    - 'hexbin' for hexagonal bin plots\n",
    "    - 'pie' for pie plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For example, to plot a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])\n",
    "\n",
    "df.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Matplotlib, we can explicitly create and keep track of the Axes objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = df.plot(kind='bar')\n",
    "ax.set_title('Axes title')\n",
    "ax.set_ylabel('Y-Axis label')\n",
    "ax.set_xlabel('X-Axis label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Exercises <a id='exercises'></a>\n",
    "> Modified from dataCamp.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I- In this exercise you will be working with vehicle data from different countries. Three lists are defined for you:\n",
    "    - names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']  \n",
    "    - names: containing the country names for which the data is available  \n",
    "    - dr =  [True, False, False, False, True, True, True]  \n",
    "    - dr: a list with booleans that tells whether people drive left or right in the corresponding country  \n",
    "    - cpc = [809, 731, 588, 18, 200, 70, 45]  \n",
    "    - cpc: the number of motor vehicles per 1000 people in the corresponding country\n",
    "\n",
    "1. Create a dictionary my_dict with three key:value pairs:\n",
    "    - key 'country' and value names\n",
    "    - key 'drives_right' and value dr\n",
    "    - key 'cars_per_cap' and value cpc\n",
    "\n",
    "2. Build a DataFrame cars from my_dict\n",
    "\n",
    "3. Check the index and columns of the DataFrame\n",
    "\n",
    "4. Override the default indexes with this list of indexes and recheck the DataFrame new index\n",
    "    - row_labels = ['US', 'AUS', 'JAP', 'IN', 'RU', 'MOR', 'EG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II- In the Example folder you have cars.csv\n",
    "\n",
    "1. Read this file as a DataFrame, and store it as cars  \n",
    "\n",
    "2. Check the index and columns of the DataFrame. Does it look correct?  \n",
    "\n",
    "3. Read the file again, but this time specify the first column in the file as an index for the DataFrame. Check the index now  \n",
    "\n",
    "4. Select the 'country' column of cars as a Pandas Series. Print result\n",
    "\n",
    "5. Select the 'country' column of cars as a Pandas DataFrame. Print result\n",
    "\n",
    "6. Select both the 'country' and 'drives_right' columns of cars. Print result\n",
    "\n",
    "7. Select the first 3 rows from cars. Print result\n",
    "\n",
    "8. Select the fourth, fifth and sixth rows (corresponding to indexes 3, 4 and 5). Print result\n",
    "\n",
    "9. Select the row corresponding to Japan as a Series (its index is 'JAP'). Print result \n",
    "\n",
    "10. Select the observations for Australia and Egypt as a DataFrame (their indexes are 'AUS', 'EG'). Print result\n",
    "\n",
    "11. Select the 'drives_right' value of the row corresponding to Morocco (its index is 'MOR')\n",
    "\n",
    "12. Select a sub-DataFrame, containing the rows for Russia and Morocco and the columns 'country' and 'drives_right' (Russia index is 'RU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Solutions <a id='solutions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "dr =  [True, False, False, False, True, True, True]\n",
    "cpc = [809, 731, 588, 18, 200, 70, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1- create dictionary my_dict\n",
    "my_dict = {'country': names, 'drives_right': dr, 'cars_per_cap': cpc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2- build a DataFrame cars\n",
    "cars = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3- check index and columns\n",
    "print(cars)\n",
    "print(cars.index)\n",
    "print(cars.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4- override default indexes and recheck\n",
    "row_labels = ['US', 'AUS', 'JAP', 'IN', 'RU', 'MOR', 'EG']\n",
    "cars.index = row_labels\n",
    "print(cars.index)\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1- read the file into a DataFrame\n",
    "cars = pd.read_csv(r'Examples/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- check index and columns \n",
    "print(cars.index)\n",
    "print(cars.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- read again with the first column as the index \n",
    "cars = pd.read_csv(r'Examples/cars.csv', index_col = 0)\n",
    "print(cars.index)\n",
    "print(cars.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- select the 'country' column as Series\n",
    "print(cars['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- select the 'country' column of as DataFrame\n",
    "print(cars[['country']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- select both 'country' and 'drives_right' columns\n",
    "print(cars[['country', 'drives_right']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7- select the first 3 rows\n",
    "print(cars.iloc[[0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8- select the fourth, fifth and sixth rows\n",
    "print(cars.iloc[3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9- select the row corresponding to Japan as a Series\n",
    "print(cars.loc[['JAP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10- select the rows corresponding for Australia and Egypt\n",
    "print(cars.loc[['AUS', 'EG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11- select the 'drives_right' value of the row corresponding to Morocco\n",
    "print(cars.loc[['MOR'],['drives_right']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12- select a DataFrame containing the rows for Russia and Morocco and the columns 'country' and 'drives_right'\n",
    "print(cars.loc[['RU', 'MOR'],['country', 'drives_right']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
